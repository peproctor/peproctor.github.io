---
---
References
==========

@book{knolldetect,
  title={Radiation Detection and Measurement},
  author={Knoll, Glenn F},
  year={2010},
  chapter = {3},
  pages= {73-76},
  publisher={John Wiley \& Sons}
}

@article{sieminski2014international,
  title="International energy outlook",
  author="Sieminski, Adam",
  journal="Energy Information Administration (EIA)",
  pages = "2",
  volume="18",
  year="2014"
}


@article{nagatani2013emergency,
  title={Emergency response to the nuclear accident at the Fukushima Daiichi Nuclear Power Plants using mobile rescue robots},
  author={Nagatani, Keiji and Kiribayashi, Seiga and Okada, Yoshito and Otake, Kazuki and Yoshida, Kazuya and Tadokoro, Satoshi and Nishimura, Takeshi and Yoshida, Tomoaki and Koyanagi, Eiji and Fukushima, Mineo and others},
  journal={Journal of Field Robotics},
  volume={30},
  number={1},
  pages={44--63},
  year={2013},
  publisher={Wiley Online Library}
}

@article{wierstra2010recurrent,
  title={Recurrent policy gradients},
  author={Wierstra, Daan and F{\"o}rster, Alexander and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={Logic Journal of the IGPL},
  volume={18},
  number={5},
  pages={620--634},
  year={2010},
  publisher={Oxford University Press}
}

@incollection{spaan2012partially,
  title={Partially observable Markov decision processes},
  author={Spaan, Matthijs TJ},
  booktitle={Reinforcement Learning},
  pages={387--414},
  year={2012},
  publisher={Springer}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@book{sutton2018rl,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{andrychowicz2020matters,
  title={What matters in on-policy reinforcement learning? A large-scale empirical study},
  author={Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and others},
  journal={arXiv preprint arXiv:2006.05990},
  year={2020}
}

@misc{abeeldeeprl,
  title={Policy Gradients},
  author={Pieter Abeel},
  publisher={Deep RL Bootcamp},
  month={August},
  year={2017}
}